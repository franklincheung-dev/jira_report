{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c264a4",
   "metadata": {},
   "source": [
    "# Agile Project Insights Dashboard - Analysis\n",
    "\n",
    "This notebook demonstrates how to use the data processing and visualization components of the Agile Project Insights Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd5587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in sample.csv:\n",
      "['Issue Type', 'Issue key', 'Issue id', 'Parent', 'Parent summary', 'Summary', 'Assignee', 'Assignee Id', 'Reporter', 'Reporter Id', 'Priority', 'Status', 'Resolution', 'Created', 'Updated', 'Due date', 'Original estimate', 'Description']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our modules\n",
    "from src.data.processor import JiraDataProcessor\n",
    "from src.visualization.charts import create_completion_donut, create_category_chart, generate_dashboard\n",
    "\n",
    "# Check for sample data\n",
    "sample_path = Path('./sample.csv')\n",
    "if sample_path.exists():\n",
    "    print(f\"Reading sample data from {sample_path}\")\n",
    "else:\n",
    "    print(f\"Sample file not found at {sample_path}. Please provide a Jira CSV export.\")\n",
    "    \n",
    "# Read the CSV file if it exists\n",
    "if sample_path.exists():\n",
    "    df = pd.read_csv(sample_path)\n",
    "    \n",
    "    # Print out all column names\n",
    "    print(\"\\nColumns in sample.csv:\")\n",
    "    print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9836196",
   "metadata": {},
   "source": [
    "## Processing the Jira Data\n",
    "\n",
    "Now we'll use the `JiraDataProcessor` class to process the data and extract insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor\n",
    "if sample_path.exists():\n",
    "    processor = JiraDataProcessor(file_path=str(sample_path))\n",
    "    \n",
    "    # Print available sprints\n",
    "    print(\"\\nAvailable Sprints:\")\n",
    "    for i, sprint in enumerate(processor.sprints):\n",
    "        print(f\"{i}: {sprint}\")\n",
    "    \n",
    "    # Get current sprint data\n",
    "    current_sprint_data = processor.get_sprint_data()\n",
    "    \n",
    "    # Print basic stats\n",
    "    print(\"\\nCurrent Sprint Stats:\")\n",
    "    print(f\"Total issues: {len(current_sprint_data)}\")\n",
    "    print(f\"Done issues: {len(current_sprint_data[current_sprint_data['Status'] == 'Done'])}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = processor.calculate_sprint_metrics()\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(\"\\nSprint Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        if key != 'blockers' and key != 'resource_utilization':\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Print category breakdown\n",
    "    print(\"\\nCategory Breakdown:\")\n",
    "    print(f\"Billable: {metrics['billable_hours']} hours\")\n",
    "    print(f\"Product: {metrics['product_hours']} hours\")\n",
    "    print(f\"Internal: {metrics['internal_hours']} hours\")\n",
    "    print(f\"Other: {metrics['other_hours']} hours\")\n",
    "    \n",
    "    # Print resource utilization\n",
    "    print(\"\\nResource Utilization:\")\n",
    "    for resource in metrics.get('resource_utilization', []):\n",
    "        print(f\"{resource['name']}: {resource['total_assigned']} hours assigned, {resource['completion_percentage']:.1f}% complete\")\n",
    "else:\n",
    "    print(\"No sample data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341141f9",
   "metadata": {},
   "source": [
    "## Creating Visualizations\n",
    "\n",
    "Now we'll generate some visualizations using the dashboard's plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf08b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if we have data\n",
    "if 'metrics' in locals():\n",
    "    # Create completion donut chart\n",
    "    completion_chart = create_completion_donut(\n",
    "        metrics['completion_percentage'],\n",
    "        metrics['total_story_points'],\n",
    "        metrics['completed_story_points']\n",
    "    )\n",
    "    \n",
    "    # Create category chart\n",
    "    category_chart = create_category_chart(\n",
    "        metrics['billable_hours'],\n",
    "        metrics['product_hours'],\n",
    "        metrics['internal_hours'],\n",
    "        metrics['other_hours']\n",
    "    )\n",
    "    \n",
    "    # Display the charts using Plotly\n",
    "    import json\n",
    "    import plotly.io as pio\n",
    "    \n",
    "    # Set the renderer to display in the notebook\n",
    "    pio.renderers.default = \"notebook\"\n",
    "    \n",
    "    # Display completion chart\n",
    "    print(\"Sprint Completion Chart:\")\n",
    "    pio.show(json.loads(completion_chart))\n",
    "    \n",
    "    # Display category chart\n",
    "    print(\"Category Breakdown Chart:\")\n",
    "    pio.show(json.loads(category_chart))\n",
    "else:\n",
    "    print(\"No metrics available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b9192",
   "metadata": {},
   "source": [
    "## Full Dashboard Generation\n",
    "\n",
    "Finally, we'll generate a complete dashboard with all charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if we have data\n",
    "if 'processor' in locals():\n",
    "    # Calculate velocity trend\n",
    "    velocity_data = processor.calculate_velocity_trend()\n",
    "    \n",
    "    # Calculate scope change\n",
    "    scope_change = processor.calculate_scope_change(current_sprint_data)\n",
    "    \n",
    "    # Project capacity\n",
    "    projected_capacity = processor.project_future_capacity()\n",
    "    \n",
    "    # Generate dashboard\n",
    "    dashboard = generate_dashboard(\n",
    "        metrics,\n",
    "        team_capacity=100,  # Example team capacity\n",
    "        velocity_data=velocity_data,\n",
    "        scope_change=scope_change,\n",
    "        projected_capacity=projected_capacity\n",
    "    )\n",
    "    \n",
    "    # Save the dashboard as a JSON file for reference\n",
    "    with open('dashboard_example.json', 'w') as f:\n",
    "        json.dump(dashboard, f, indent=2)\n",
    "    \n",
    "    print(\"Dashboard generated and saved to dashboard_example.json\")\n",
    "else:\n",
    "    print(\"No processor available for dashboard generation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
